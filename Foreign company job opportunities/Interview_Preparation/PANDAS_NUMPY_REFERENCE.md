# Pandas & Numpy å‡½æ•°é€ŸæŸ¥æ‰‹å†Œ ğŸ“š

> åŸºäº python_interview_questions.py ä¸­çš„çœŸå®é¢è¯•é¢˜æ•´ç†
> ä¸“ä¸ºå¤–ä¼æ•°æ®å²—ä½é¢è¯•å‡†å¤‡

---

## ç›®å½•

1. [Pandas DataFrame åŸºç¡€æ“ä½œ](#1-pandas-dataframe-åŸºç¡€æ“ä½œ)
2. [æ•°æ®æ¸…æ´—å‡½æ•°](#2-æ•°æ®æ¸…æ´—å‡½æ•°)
3. [æ•°æ®åˆ†ç»„å’Œèšåˆ](#3-æ•°æ®åˆ†ç»„å’Œèšåˆ)
4. [æ•°æ®è½¬æ¢å’Œé‡å¡‘](#4-æ•°æ®è½¬æ¢å’Œé‡å¡‘)
5. [æ—¶é—´åºåˆ—å¤„ç†](#5-æ—¶é—´åºåˆ—å¤„ç†)
6. [æ•°æ®åˆå¹¶å’Œå…³è”](#6-æ•°æ®åˆå¹¶å’Œå…³è”)
7. [æ–‡ä»¶è¯»å†™](#7-æ–‡ä»¶è¯»å†™)
8. [æ•°æ®éªŒè¯](#8-æ•°æ®éªŒè¯)
9. [Numpy å¸¸ç”¨å‡½æ•°](#9-numpy-å¸¸ç”¨å‡½æ•°)

---

## 1. Pandas DataFrame åŸºç¡€æ“ä½œ

### 1.1 pd.DataFrame()

**åŠŸèƒ½**: åˆ›å»º DataFrame

**è¯­æ³•**:
```python
pd.DataFrame(data, index=None, columns=None)
```

**å‚æ•°**:
- `data`: å­—å…¸ã€åˆ—è¡¨ã€numpyæ•°ç»„ç­‰
- `index`: è¡Œç´¢å¼•
- `columns`: åˆ—å

**ç¤ºä¾‹**:
```python
import pandas as pd
import numpy as np

# ä»å­—å…¸åˆ›å»º
data = {
    'name': ['Alice', 'Bob', 'Charlie'],
    'age': [25, 30, 35],
    'city': ['NYC', 'LA', 'SF']
}
df = pd.DataFrame(data)

# ä»åˆ—è¡¨åˆ›å»º
data = [['Alice', 25], ['Bob', 30]]
df = pd.DataFrame(data, columns=['name', 'age'])

# ä»numpyæ•°ç»„åˆ›å»º
arr = np.array([[1, 2], [3, 4]])
df = pd.DataFrame(arr, columns=['A', 'B'])
```

**é¢è¯•è¦ç‚¹**:
- æœ€å¸¸ç”¨çš„æ•°æ®ç»“æ„åˆ›å»ºæ–¹å¼
- äº†è§£å¦‚ä½•ä»ä¸åŒæ•°æ®æºåˆ›å»ºDataFrame
- æ³¨æ„åˆ—åå’Œç´¢å¼•çš„è®¾ç½®

---

### 1.2 df.reset_index()

**åŠŸèƒ½**: é‡ç½®DataFrameçš„ç´¢å¼•

**è¯­æ³•**:
```python
df.reset_index(drop=False, inplace=False)
```

**å‚æ•°**:
- `drop`: æ˜¯å¦åˆ é™¤åŸç´¢å¼•åˆ— (True/False)
- `inplace`: æ˜¯å¦åŸåœ°ä¿®æ”¹ (True/False)

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie'],
    'age': [25, 30, 35]
}, index=[10, 20, 30])

# drop=False: ä¿ç•™åŸç´¢å¼•ä½œä¸ºåˆ—
df_reset = df.reset_index()
#    index    name  age
# 0     10   Alice   25
# 1     20     Bob   30
# 2     30 Charlie   35

# drop=True: åˆ é™¤åŸç´¢å¼•
df_reset = df.reset_index(drop=True)
#       name  age
# 0    Alice   25
# 1      Bob   30
# 2  Charlie   35
```

**å¸¸è§åœºæ™¯**:
```python
# æ•°æ®æ¸…æ´—åé‡ç½®ç´¢å¼•
df = df.drop_duplicates()
df = df.reset_index(drop=True)  # ç´¢å¼•å˜ä¸º0,1,2...

# åˆ†ç»„åé‡ç½®ç´¢å¼•
result = df.groupby('category').agg({'price': 'mean'}).reset_index()
```

**é¢è¯•è¦ç‚¹**:
- åˆ é™¤é‡å¤è¡Œã€åˆ é™¤ç‰¹å®šè¡Œåï¼Œç´¢å¼•ä¼šä¸è¿ç»­
- ä½¿ç”¨ `drop=True` é¿å…ä¿ç•™æ— ç”¨çš„æ—§ç´¢å¼•åˆ—
- åˆ†ç»„èšåˆåé€šå¸¸éœ€è¦ reset_index()

---

## 2. æ•°æ®æ¸…æ´—å‡½æ•°

### 2.1 df.drop_duplicates() â­â­â­â­â­

**åŠŸèƒ½**: åˆ é™¤é‡å¤çš„è¡Œ

**è¯­æ³•**:
```python
df.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)
```

**å‚æ•°**:
- `subset`: æŒ‡å®šç”¨äºåˆ¤æ–­é‡å¤çš„åˆ— (list)
- `keep`: 'first'(ä¿ç•™ç¬¬ä¸€ä¸ª) | 'last'(ä¿ç•™æœ€åä¸€ä¸ª) | False(åˆ é™¤æ‰€æœ‰é‡å¤)
- `inplace`: æ˜¯å¦åŸåœ°ä¿®æ”¹
- `ignore_index`: æ˜¯å¦é‡ç½®ç´¢å¼•

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Alice', 'David'],
    'age': [25, 30, 25, 35],
    'city': ['NYC', 'LA', 'NYC', 'SF']
})

# åˆ é™¤å®Œå…¨ç›¸åŒçš„è¡Œ
df.drop_duplicates()
#     name  age city
# 0  Alice   25  NYC
# 1    Bob   30   LA
# 3  David   35   SF

# åªæ ¹æ®nameåˆ—åˆ¤æ–­é‡å¤
df.drop_duplicates(subset=['name'])
#     name  age city
# 0  Alice   25  NYC
# 1    Bob   30   LA
# 3  David   35   SF

# ä¿ç•™æœ€åä¸€ä¸ª
df.drop_duplicates(subset=['name'], keep='last')

# åˆ é™¤æ‰€æœ‰é‡å¤ï¼ˆä¸€ä¸ªéƒ½ä¸ä¿ç•™ï¼‰
df.drop_duplicates(subset=['name'], keep=False)

# åŸåœ°ä¿®æ”¹ + é‡ç½®ç´¢å¼•
df.drop_duplicates(inplace=True, ignore_index=True)
```

**é¢è¯•çœŸé¢˜åº”ç”¨**:
```python
# é¢˜ç›®1: æ•°æ®æ¸…æ´—
def clean_dataframe(df):
    # æ­¥éª¤1: åˆ é™¤é‡å¤è¡Œ
    df = df.drop_duplicates()

    # æ­¥éª¤2: å¤„ç†ç¼ºå¤±å€¼
    mean_age = df['age'].mean()
    df['age'] = df['age'].fillna(mean_age)

    # æ­¥éª¤3: åˆ é™¤å…³é”®åˆ—ä¸ºç©ºçš„è¡Œ
    df = df.dropna(subset=['name'])

    return df.reset_index(drop=True)
```

**é¢è¯•è¦ç‚¹**:
- **æœ€é«˜é¢‘è€ƒç‚¹**ï¼Œå‡ ä¹æ¯æ¬¡é¢è¯•éƒ½ä¼šæ¶‰åŠ
- æ³¨æ„ `subset` å‚æ•°çš„ä½¿ç”¨
- å¤šä¸ªNaNå€¼è¢«è§†ä¸ºç›¸åŒ
- åˆ é™¤åç´¢å¼•ä¸è¿ç»­ï¼Œéœ€è¦ reset_index()

---

### 2.2 df.fillna()

**åŠŸèƒ½**: å¡«å……ç¼ºå¤±å€¼

**è¯­æ³•**:
```python
df.fillna(value, method=None, inplace=False)
```

**å‚æ•°**:
- `value`: å¡«å……å€¼ï¼ˆå¯ä»¥æ˜¯æ ‡é‡ã€å­—å…¸ã€Seriesç­‰ï¼‰
- `method`: 'ffill'(å‰å‘å¡«å……) | 'bfill'(åå‘å¡«å……)
- `inplace`: æ˜¯å¦åŸåœ°ä¿®æ”¹

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'A': [1, np.nan, 3],
    'B': [4, 5, np.nan],
    'C': [np.nan, 8, 9]
})

# ç”¨0å¡«å……æ‰€æœ‰ç¼ºå¤±å€¼
df.fillna(0)
#      A    B    C
# 0  1.0  4.0  0.0
# 1  0.0  5.0  8.0
# 2  3.0  0.0  9.0

# ç”¨å‡å€¼å¡«å……
df['A'].fillna(df['A'].mean())

# ä¸åŒåˆ—ç”¨ä¸åŒå€¼å¡«å……
df.fillna({'A': 0, 'B': df['B'].mean(), 'C': -1})

# å‰å‘å¡«å……ï¼ˆç”¨å‰ä¸€ä¸ªå€¼å¡«å……ï¼‰
df.fillna(method='ffill')

# åå‘å¡«å……ï¼ˆç”¨åä¸€ä¸ªå€¼å¡«å……ï¼‰
df.fillna(method='bfill')
```

**å¸¸è§æ¨¡å¼**:
```python
# æ•°å€¼åˆ—ç”¨å‡å€¼å¡«å……
df['age'].fillna(df['age'].mean(), inplace=True)

# æ•°å€¼åˆ—ç”¨ä¸­ä½æ•°å¡«å……
df['salary'].fillna(df['salary'].median(), inplace=True)

# åˆ†ç±»åˆ—ç”¨ä¼—æ•°å¡«å……
df['category'].fillna(df['category'].mode()[0], inplace=True)

# å­—ç¬¦ä¸²åˆ—ç”¨å›ºå®šå€¼å¡«å……
df['city'].fillna('Unknown', inplace=True)
```

**é¢è¯•è¦ç‚¹**:
- å¿…é¡»ç†è§£ä¸åŒå¡«å……ç­–ç•¥çš„é€‚ç”¨åœºæ™¯
- å‡å€¼é€‚ç”¨äºæ­£æ€åˆ†å¸ƒæ•°æ®
- ä¸­ä½æ•°é€‚ç”¨äºæœ‰å¼‚å¸¸å€¼çš„æ•°æ®
- ä¼—æ•°é€‚ç”¨äºåˆ†ç±»æ•°æ®

---

### 2.3 df.dropna()

**åŠŸèƒ½**: åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œæˆ–åˆ—

**è¯­æ³•**:
```python
df.dropna(axis=0, how='any', subset=None, inplace=False)
```

**å‚æ•°**:
- `axis`: 0(åˆ é™¤è¡Œ) | 1(åˆ é™¤åˆ—)
- `how`: 'any'(ä»»ä½•ç¼ºå¤±) | 'all'(å…¨éƒ¨ç¼ºå¤±)
- `subset`: æŒ‡å®šæ£€æŸ¥ç¼ºå¤±å€¼çš„åˆ—
- `inplace`: æ˜¯å¦åŸåœ°ä¿®æ”¹

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'name': ['Alice', 'Bob', None, 'David'],
    'age': [25, np.nan, 30, 35],
    'city': ['NYC', 'LA', 'SF', None]
})

# åˆ é™¤ä»»ä½•åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ
df.dropna()
#     name   age city
# 0  Alice  25.0  NYC

# åˆ é™¤å…¨éƒ¨ä¸ºç¼ºå¤±å€¼çš„è¡Œ
df.dropna(how='all')

# åªæ£€æŸ¥ç‰¹å®šåˆ—çš„ç¼ºå¤±å€¼
df.dropna(subset=['name'])
#     name   age city
# 0  Alice  25.0  NYC
# 1    Bob   NaN   LA
# 3  David  35.0 None

# åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„åˆ—
df.dropna(axis=1)
```

**é¢è¯•çœŸé¢˜åº”ç”¨**:
```python
# ç»„åˆä½¿ç”¨
def clean_data(df):
    # åˆ é™¤å…³é”®åˆ—ä¸ºç©ºçš„è¡Œï¼ˆå¦‚IDã€ä¸»é”®ï¼‰
    df = df.dropna(subset=['id', 'customer_id'])

    # å…¶ä»–åˆ—ç”¨åˆé€‚çš„å€¼å¡«å……
    df['age'].fillna(df['age'].mean(), inplace=True)
    df['category'].fillna('Unknown', inplace=True)

    return df
```

**é¢è¯•è¦ç‚¹**:
- ç†è§£ä½•æ—¶åˆ é™¤ã€ä½•æ—¶å¡«å……
- å…³é”®ä¸šåŠ¡å­—æ®µç¼ºå¤± â†’ åˆ é™¤è¡Œ
- å¯æ¨æ–­çš„å­—æ®µç¼ºå¤± â†’ å¡«å……å€¼

---

### 2.4 df['col'].mean() / sum() / median()

**åŠŸèƒ½**: è®¡ç®—åˆ—çš„ç»Ÿè®¡å€¼

**å¸¸ç”¨ç»Ÿè®¡å‡½æ•°**:
```python
df['age'].mean()      # å¹³å‡å€¼
df['age'].median()    # ä¸­ä½æ•°
df['age'].sum()       # æ€»å’Œ
df['age'].min()       # æœ€å°å€¼
df['age'].max()       # æœ€å¤§å€¼
df['age'].std()       # æ ‡å‡†å·®
df['age'].var()       # æ–¹å·®
df['age'].count()     # éç©ºå€¼æ•°é‡
```

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie'],
    'age': [25, 30, 35],
    'salary': [50000, 60000, 70000]
})

# è®¡ç®—å¹³å‡å¹´é¾„
avg_age = df['age'].mean()  # 30.0

# è®¡ç®—æ€»è–ªèµ„
total_salary = df['salary'].sum()  # 180000

# å¤„ç†ç¼ºå¤±å€¼æ—¶
df_with_na = pd.DataFrame({
    'age': [25, np.nan, 35]
})
df_with_na['age'].mean()  # 30.0 (è‡ªåŠ¨å¿½ç•¥NaN)
```

**é¢è¯•çœŸé¢˜åº”ç”¨**:
```python
# é¢˜ç›®1: ç”¨å‡å€¼å¡«å……ç¼ºå¤±å€¼
mean_age = df['age'].mean()
df['age'] = df['age'].fillna(mean_age)

# é¢˜ç›®20: æ£€æµ‹å¼‚å¸¸å€¼ï¼ˆ3ÏƒåŸåˆ™ï¼‰
mean = df['amount'].mean()
std = df['amount'].std()
outliers = df[(df['amount'] < mean - 3*std) | (df['amount'] > mean + 3*std)]
```

**é¢è¯•è¦ç‚¹**:
- è¿™äº›å‡½æ•°é»˜è®¤å¿½ç•¥ NaN
- å¯ä»¥ç”¨ `skipna=False` å‚æ•°ä½¿ç»“æœä¸º NaN

---

## 3. æ•°æ®åˆ†ç»„å’Œèšåˆ

### 3.1 df.groupby() â­â­â­â­â­

**åŠŸèƒ½**: æŒ‰ç…§ä¸€åˆ—æˆ–å¤šåˆ—å¯¹æ•°æ®è¿›è¡Œåˆ†ç»„

**è¯­æ³•**:
```python
df.groupby(by=None, as_index=True)
```

**å‚æ•°**:
- `by`: åˆ†ç»„çš„åˆ—åï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
- `as_index`: æ˜¯å¦å°†åˆ†ç»„åˆ—ä½œä¸ºç´¢å¼•

**åŸºæœ¬ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'product': ['iPhone', 'MacBook', 'iPhone', 'AirPods'],
    'category': ['Electronics', 'Electronics', 'Electronics', 'Electronics'],
    'price': [1000, 2000, 1000, 200],
    'quantity': [2, 1, 3, 5]
})

# æŒ‰productåˆ†ç»„ï¼Œè®¡ç®—æ€»æ•°é‡
df.groupby('product')['quantity'].sum()
# product
# AirPods     5
# MacBook     1
# iPhone      5

# æŒ‰å¤šåˆ—åˆ†ç»„
df.groupby(['category', 'product'])['price'].mean()
```

**å¸¸ç”¨èšåˆæ“ä½œ**:
```python
# å•ä¸ªèšåˆ
df.groupby('product')['price'].mean()
df.groupby('product')['quantity'].sum()
df.groupby('product')['price'].count()

# å¤šä¸ªèšåˆï¼ˆä½¿ç”¨aggï¼‰
df.groupby('product').agg({
    'price': 'mean',
    'quantity': 'sum'
})

# å¯¹åŒä¸€åˆ—ä½¿ç”¨å¤šä¸ªèšåˆ
df.groupby('product')['price'].agg(['mean', 'min', 'max', 'count'])

# è‡ªå®šä¹‰èšåˆå‡½æ•°
df.groupby('product')['price'].agg(lambda x: x.max() - x.min())
```

**é¢è¯•çœŸé¢˜åº”ç”¨**:
```python
# é¢˜ç›®2: æ•°æ®åˆ†ç»„èšåˆ
def analyze_sales(df):
    # è®¡ç®—revenue
    df['revenue'] = df['price'] * df['quantity']

    # åˆ†ç»„èšåˆ
    summary = df.groupby('product').agg({
        'revenue': 'sum',        # æ€»æ”¶å…¥
        'price': 'mean',         # å¹³å‡ä»·æ ¼
        'product': 'count'       # é”€å”®æ¬¡æ•°
    }).reset_index()

    # é‡å‘½ååˆ—
    summary.columns = ['product', 'total_revenue', 'avg_price', 'num_sales']

    return summary
```

**å¸¸è§åˆ†ç»„æ¨¡å¼**:
```python
# 1. æŒ‰ç±»åˆ«ç»Ÿè®¡
category_stats = df.groupby('category').agg({
    'sales': ['sum', 'mean', 'count'],
    'revenue': 'sum'
})

# 2. æŒ‰æ—¶é—´åˆ†ç»„ï¼ˆå¹´ã€æœˆã€å‘¨ï¼‰
df['date'] = pd.to_datetime(df['date'])
df.groupby(df['date'].dt.year)['sales'].sum()
df.groupby(df['date'].dt.month)['sales'].mean()

# 3. æŒ‰å¤šä¸ªç»´åº¦åˆ†ç»„
df.groupby(['region', 'category'])['sales'].sum()

# 4. åº”ç”¨è‡ªå®šä¹‰å‡½æ•°åˆ°æ¯ä¸ªç»„
def custom_agg(group):
    return group['price'].max() - group['price'].min()

df.groupby('category').apply(custom_agg)
```

**é¢è¯•è¦ç‚¹**:
- **è¶…é«˜é¢‘è€ƒç‚¹**ï¼Œå¿…é¡»ç†Ÿç»ƒæŒæ¡
- ç†è§£ split-apply-combine æ¨¡å¼
- æŒæ¡å¸¸è§èšåˆå‡½æ•°ï¼šsum, mean, count, min, max
- äº†è§£å¦‚ä½•åŒæ—¶åº”ç”¨å¤šä¸ªèšåˆå‡½æ•°
- è®°å¾—ä½¿ç”¨ `reset_index()` å°†åˆ†ç»„åˆ—å˜å›æ™®é€šåˆ—

---

### 3.2 df.agg()

**åŠŸèƒ½**: å¯¹DataFrameæˆ–åˆ†ç»„å¯¹è±¡åº”ç”¨èšåˆå‡½æ•°

**è¯­æ³•**:
```python
df.agg(func, axis=0)
grouped.agg(func_dict)
```

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6],
    'C': [7, 8, 9]
})

# å¯¹æ‰€æœ‰åˆ—åº”ç”¨å•ä¸ªå‡½æ•°
df.agg('sum')
# A     6
# B    15
# C    24

# å¯¹æ‰€æœ‰åˆ—åº”ç”¨å¤šä¸ªå‡½æ•°
df.agg(['sum', 'mean', 'std'])
#             A         B         C
# sum   6.000000  15.000000  24.000000
# mean  2.000000   5.000000   8.000000
# std   1.000000   1.000000   1.000000

# ä¸åŒåˆ—åº”ç”¨ä¸åŒå‡½æ•°
df.agg({
    'A': 'sum',
    'B': 'mean',
    'C': ['min', 'max']
})
```

**ä¸groupbyç»“åˆ**:
```python
# æœ€å¸¸è§ç”¨æ³•
df.groupby('category').agg({
    'price': 'mean',
    'quantity': 'sum',
    'revenue': ['sum', 'mean']
})

# ä½¿ç”¨å‘½åèšåˆï¼ˆpandas 0.25+ï¼‰
df.groupby('category').agg(
    avg_price=('price', 'mean'),
    total_qty=('quantity', 'sum'),
    max_revenue=('revenue', 'max')
)
```

**é¢è¯•è¦ç‚¹**:
- ä¸ groupby é…åˆä½¿ç”¨æœ€é¢‘ç¹
- äº†è§£å¦‚ä½•å¯¹ä¸åŒåˆ—åº”ç”¨ä¸åŒèšåˆ
- æŒæ¡å¸¸ç”¨èšåˆå‡½æ•°åç§°

---

### 3.3 df.sort_values()

**åŠŸèƒ½**: æŒ‰ç…§ä¸€åˆ—æˆ–å¤šåˆ—å¯¹DataFrameæ’åº

**è¯­æ³•**:
```python
df.sort_values(by, ascending=True, inplace=False)
```

**å‚æ•°**:
- `by`: æ’åºçš„åˆ—åï¼ˆå­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
- `ascending`: True(å‡åº) | False(é™åº)ï¼Œå¯ä»¥æ˜¯å¸ƒå°”å€¼åˆ—è¡¨
- `inplace`: æ˜¯å¦åŸåœ°ä¿®æ”¹

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Charlie', 'David'],
    'age': [25, 30, 25, 35],
    'salary': [50000, 60000, 55000, 70000]
})

# æŒ‰å•åˆ—æ’åºï¼ˆå‡åºï¼‰
df.sort_values('age')

# æŒ‰å•åˆ—æ’åºï¼ˆé™åºï¼‰
df.sort_values('age', ascending=False)

# æŒ‰å¤šåˆ—æ’åºï¼ˆå…ˆæŒ‰ageå‡åºï¼Œå†æŒ‰salaryé™åºï¼‰
df.sort_values(['age', 'salary'], ascending=[True, False])
#       name  age  salary
# 2  Charlie   25   55000
# 0    Alice   25   50000
# 1      Bob   30   60000
# 3    David   35   70000
```

**é¢è¯•çœŸé¢˜åº”ç”¨**:
```python
# é¢˜ç›®2: åˆ†ç»„èšåˆåæ’åº
summary = df.groupby('product').agg({
    'revenue': 'sum'
}).reset_index()

# æŒ‰revenueé™åºæ’åˆ—
summary = summary.sort_values('revenue', ascending=False)

# é¢˜ç›®13: å­—å…¸æ’åºè½¬DataFrame
sorted_items = sorted(d.items(), key=lambda x: (-x[1], x[0]))
```

**é¢è¯•è¦ç‚¹**:
- å¯ä»¥æŒ‰å¤šåˆ—æ’åºï¼Œæ³¨æ„ ascending å‚æ•°å¯ä»¥æ˜¯åˆ—è¡¨
- æ’åºåç´¢å¼•é¡ºåºä¼šæ”¹å˜ï¼Œå¯èƒ½éœ€è¦ reset_index()
- é»˜è®¤ NaN æ’åœ¨æœ€å

---

### 3.4 df['col'].value_counts()

**åŠŸèƒ½**: ç»Ÿè®¡æ¯ä¸ªå€¼å‡ºç°çš„æ¬¡æ•°

**è¯­æ³•**:
```python
df['col'].value_counts(normalize=False, sort=True, ascending=False)
```

**å‚æ•°**:
- `normalize`: Trueè¿”å›å æ¯”ï¼ŒFalseè¿”å›è®¡æ•°
- `sort`: æ˜¯å¦æ’åº
- `ascending`: æ’åºæ–¹å‘

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'category': ['A', 'B', 'A', 'C', 'B', 'A', 'A']
})

# ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ•°é‡
df['category'].value_counts()
# A    4
# B    2
# C    1

# è¿”å›å æ¯”
df['category'].value_counts(normalize=True)
# A    0.571429
# B    0.285714
# C    0.142857

# å‡åºæ’åˆ—
df['category'].value_counts(ascending=True)
```

**é¢è¯•åº”ç”¨**:
```python
# æ‰¾å‡ºæœ€å¸¸è§çš„ç±»åˆ«
most_common = df['category'].value_counts().index[0]

# æ‰¾å‡ºTop 3ç±»åˆ«
top3 = df['category'].value_counts().head(3)

# è½¬æ¢ä¸ºå­—å…¸
category_counts = df['category'].value_counts().to_dict()
```

**é¢è¯•è¦ç‚¹**:
- è¿”å› Seriesï¼Œç´¢å¼•æ˜¯å€¼ï¼Œæ•°æ®æ˜¯è®¡æ•°
- é»˜è®¤æŒ‰è®¡æ•°é™åºæ’åˆ—
- å¸¸ç”¨äºåˆ†ç±»æ•°æ®çš„é¢‘ç‡åˆ†æ

---

## 4. æ•°æ®è½¬æ¢å’Œé‡å¡‘

### 4.1 df.pivot() â­â­â­â­

**åŠŸèƒ½**: å°†é•¿æ ¼å¼æ•°æ®è½¬æ¢ä¸ºå®½æ ¼å¼ï¼ˆæ•°æ®é€è§†ï¼‰

**è¯­æ³•**:
```python
df.pivot(index, columns, values)
```

**å‚æ•°**:
- `index`: ç”¨ä½œæ–°DataFrameç´¢å¼•çš„åˆ—
- `columns`: ç”¨ä½œæ–°DataFrameåˆ—åçš„åˆ—
- `values`: ç”¨ä½œæ–°DataFrameå€¼çš„åˆ—

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'date': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02'],
    'product': ['A', 'B', 'A', 'B'],
    'sales': [100, 200, 150, 250]
})

# é€è§†ï¼šdateä¸ºè¡Œï¼Œproductä¸ºåˆ—
pivoted = df.pivot(index='date', columns='product', values='sales')

# ç»“æœï¼š
# product       A    B
# date
# 2024-01-01  100  200
# 2024-01-02  150  250
```

**é¢è¯•çœŸé¢˜åº”ç”¨**:
```python
# é¢˜ç›®3: æ•°æ®é€è§†
def pivot_sales_data(df):
    """å°†é•¿æ ¼å¼é”€å”®æ•°æ®è½¬ä¸ºå®½æ ¼å¼"""
    pivoted = df.pivot(index='date', columns='product', values='sales')
    return pivoted
```

**å¸¸è§ç”¨æ³•**:
```python
# ç”¨æˆ·-å•†å“è´­ä¹°çŸ©é˜µ
user_product_matrix = df.pivot(
    index='user_id',
    columns='product_id',
    values='purchase_count'
)

# æ—¥æœŸ-ç±»åˆ«é”€å”®è¡¨
date_category_sales = df.pivot(
    index='date',
    columns='category',
    values='sales_amount'
)
```

**ä¸ pivot_table çš„åŒºåˆ«**:
```python
# pivot: ä¸èƒ½æœ‰é‡å¤çš„index-columnç»„åˆï¼Œä¸èƒ½èšåˆ
df.pivot(index='date', columns='product', values='sales')

# pivot_table: å¯ä»¥æœ‰é‡å¤ï¼Œå¯ä»¥èšåˆ
df.pivot_table(
    index='date',
    columns='product',
    values='sales',
    aggfunc='sum'  # æˆ– 'mean', 'count' ç­‰
)
```

**é¢è¯•è¦ç‚¹**:
- ç†è§£é•¿æ ¼å¼ vs å®½æ ¼å¼çš„æ¦‚å¿µ
- pivot è¦æ±‚ index-column ç»„åˆå”¯ä¸€
- å¦‚æœæœ‰é‡å¤ï¼Œä½¿ç”¨ pivot_table
- å¸¸ç”¨äºåˆ›å»ºäº¤å‰è¡¨ã€ç”¨æˆ·-ç‰©å“çŸ©é˜µ

---

## 5. æ—¶é—´åºåˆ—å¤„ç†

### 5.1 pd.to_datetime() â­â­â­â­

**åŠŸèƒ½**: å°†å­—ç¬¦ä¸²æˆ–æ•°å­—è½¬æ¢ä¸ºdatetimeç±»å‹

**è¯­æ³•**:
```python
pd.to_datetime(arg, format=None, errors='raise')
```

**å‚æ•°**:
- `arg`: è¦è½¬æ¢çš„æ•°æ®
- `format`: æ—¥æœŸæ ¼å¼ï¼ˆå¦‚'%Y-%m-%d'ï¼‰
- `errors`: 'raise'(æŠ¥é”™) | 'coerce'(è½¬ä¸ºNaT) | 'ignore'(ä¿æŒåŸæ ·)

**ç¤ºä¾‹**:
```python
# è½¬æ¢å­—ç¬¦ä¸²
dates = ['2024-01-01', '2024-01-02', '2024-01-03']
pd.to_datetime(dates)
# DatetimeIndex(['2024-01-01', '2024-01-02', '2024-01-03'])

# è½¬æ¢DataFrameä¸­çš„åˆ—
df['date'] = pd.to_datetime(df['date'])

# æŒ‡å®šæ ¼å¼
df['date'] = pd.to_datetime(df['date'], format='%Y/%m/%d')

# å¤„ç†é”™è¯¯
df['date'] = pd.to_datetime(df['date'], errors='coerce')  # æ— æ•ˆæ—¥æœŸå˜ä¸ºNaT

# ä»å¤šä¸ªåˆ—åˆ›å»ºæ—¥æœŸ
df['date'] = pd.to_datetime(df[['year', 'month', 'day']])
```

**æ—¥æœŸæ—¶é—´è®¿é—®**:
```python
df['date'] = pd.to_datetime(df['date'])

# æå–å¹´æœˆæ—¥
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df['weekday'] = df['date'].dt.dayofweek  # 0=Monday, 6=Sunday
df['quarter'] = df['date'].dt.quarter

# æ ¼å¼åŒ–è¾“å‡º
df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')
```

**é¢è¯•çœŸé¢˜åº”ç”¨**:
```python
# é¢˜ç›®4: æ—¶é—´åºåˆ—å¤„ç†
def analyze_timeseries(df):
    # è½¬æ¢ä¸ºdatetime
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.set_index('timestamp')

    # æŒ‰æ—¥èšåˆ
    daily_avg = df.resample('D').mean()

    return daily_avg
```

**å¸¸è§æ—¥æœŸæ ¼å¼**:
```python
# ISO æ ¼å¼ï¼ˆè‡ªåŠ¨è¯†åˆ«ï¼‰
pd.to_datetime('2024-01-15')

# ç¾å›½æ ¼å¼
pd.to_datetime('01/15/2024', format='%m/%d/%Y')

# ä¸­æ–‡æ ¼å¼
pd.to_datetime('2024å¹´1æœˆ15æ—¥', format='%Yå¹´%mæœˆ%dæ—¥')

# Unixæ—¶é—´æˆ³
pd.to_datetime(1705276800, unit='s')
```

**é¢è¯•è¦ç‚¹**:
- å‡ ä¹æ‰€æœ‰æ—¶é—´åºåˆ—åˆ†æçš„ç¬¬ä¸€æ­¥
- äº†è§£å¸¸è§æ—¥æœŸæ ¼å¼
- ä½¿ç”¨ `errors='coerce'` å¤„ç†è„æ•°æ®
- è½¬æ¢åå¯ä»¥ä½¿ç”¨ `.dt` è®¿é—®å™¨æå–æ—¥æœŸéƒ¨åˆ†

---

### 5.2 df.set_index()

**åŠŸèƒ½**: å°†æŸåˆ—è®¾ç½®ä¸ºDataFrameçš„ç´¢å¼•

**è¯­æ³•**:
```python
df.set_index(keys, drop=True, inplace=False)
```

**å‚æ•°**:
- `keys`: è¦è®¾ç½®ä¸ºç´¢å¼•çš„åˆ—å
- `drop`: æ˜¯å¦åˆ é™¤åŸåˆ—
- `inplace`: æ˜¯å¦åŸåœ°ä¿®æ”¹

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'date': ['2024-01-01', '2024-01-02', '2024-01-03'],
    'value': [100, 150, 200]
})

# å°†dateåˆ—è®¾ä¸ºç´¢å¼•
df_indexed = df.set_index('date')
#              value
# date
# 2024-01-01    100
# 2024-01-02    150
# 2024-01-03    200

# è®¾ç½®å¤šå±‚ç´¢å¼•
df.set_index(['date', 'category'])

# ä¸åˆ é™¤åŸåˆ—
df.set_index('date', drop=False)
```

**æ—¶é—´åºåˆ—å¸¸è§ç”¨æ³•**:
```python
# æ—¶é—´åºåˆ—åˆ†ææ ‡å‡†æµç¨‹
df['timestamp'] = pd.to_datetime(df['timestamp'])
df = df.set_index('timestamp')

# ç°åœ¨å¯ä»¥ä½¿ç”¨æ—¶é—´ç´¢å¼•çš„åŠŸèƒ½
df['2024-01']  # é€‰æ‹©2024å¹´1æœˆçš„æ•°æ®
df['2024-01':'2024-03']  # é€‰æ‹©æ—¶é—´èŒƒå›´
df.resample('D').mean()  # æŒ‰æ—¥é‡é‡‡æ ·
```

**é¢è¯•è¦ç‚¹**:
- æ—¶é—´åºåˆ—åˆ†æé€šå¸¸éœ€è¦å°†æ—¶é—´åˆ—è®¾ä¸ºç´¢å¼•
- è®¾ç½®ç´¢å¼•åå¯ä»¥ä½¿ç”¨æ—¶é—´åˆ‡ç‰‡
- ä½¿ç”¨ `reset_index()` å¯ä»¥è¿˜åŸä¸ºæ™®é€šåˆ—

---

### 5.3 df.resample() â­â­â­

**åŠŸèƒ½**: å¯¹æ—¶é—´åºåˆ—æ•°æ®è¿›è¡Œé‡é‡‡æ ·ï¼ˆé™é‡‡æ ·æˆ–å‡é‡‡æ ·ï¼‰

**å‰æ**: DataFrameå¿…é¡»æœ‰DatetimeIndex

**è¯­æ³•**:
```python
df.resample(rule).agg_func()
```

**å‚æ•° rule**:
- `'D'`: å¤©
- `'W'`: å‘¨
- `'M'`: æœˆæœ«
- `'MS'`: æœˆåˆ
- `'Q'`: å­£åº¦æœ«
- `'Y'`: å¹´æœ«
- `'H'`: å°æ—¶
- `'T'` æˆ– `'min'`: åˆ†é’Ÿ

**ç¤ºä¾‹**:
```python
# åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
dates = pd.date_range('2024-01-01', periods=30, freq='D')
df = pd.DataFrame({
    'value': np.random.randint(100, 200, 30)
}, index=dates)

# æŒ‰å‘¨èšåˆï¼ˆæ±‚å’Œï¼‰
weekly = df.resample('W').sum()

# æŒ‰æœˆèšåˆï¼ˆæ±‚å¹³å‡ï¼‰
monthly = df.resample('M').mean()

# æŒ‰å­£åº¦èšåˆ
quarterly = df.resample('Q').sum()

# é™é‡‡æ ·ï¼šä»å°æ—¶åˆ°å¤©
hourly_data.resample('D').mean()

# å¤šä¸ªèšåˆ
df.resample('M').agg(['sum', 'mean', 'count'])
```

**é¢è¯•çœŸé¢˜åº”ç”¨**:
```python
# é¢˜ç›®4: æ—¶é—´åºåˆ—åˆ†æ
def analyze_timeseries(df):
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.set_index('timestamp')

    # æ¯æ—¥å¹³å‡å€¼
    daily_avg = df.resample('D').mean()

    # æ¯æœˆæ€»å’Œ
    monthly_sum = df.resample('M').sum()

    # æ¯æœˆç¯æ¯”å¢é•¿
    monthly_sum['mom_growth'] = monthly_sum['value'].pct_change() * 100

    return daily_avg, monthly_sum
```

**å¸¸è§åº”ç”¨**:
```python
# ä»åˆ†é’Ÿçº§åˆ°å°æ—¶çº§
df.resample('H').mean()

# ä»æ—¥çº§åˆ°å‘¨çº§
df.resample('W-MON').sum()  # å‘¨ä¸€ä¸ºèµ·å§‹æ—¥

# ä»æ—¥çº§åˆ°æœˆçº§ï¼ˆä¿ç•™å¤šåˆ—ï¼‰
df.resample('M').agg({
    'sales': 'sum',
    'quantity': 'sum',
    'price': 'mean'
})
```

**é¢è¯•è¦ç‚¹**:
- å¿…é¡»å…ˆæœ‰ DatetimeIndexï¼ˆä½¿ç”¨ set_indexï¼‰
- ç†è§£é™é‡‡æ ·ï¼ˆèšåˆï¼‰vs å‡é‡‡æ ·ï¼ˆæ’å€¼ï¼‰
- æŒæ¡å¸¸ç”¨çš„æ—¶é—´é¢‘ç‡ä»£ç 
- ä¸åŒæŒ‡æ ‡ç”¨ä¸åŒèšåˆï¼šé”€å”®é¢ç”¨sumï¼Œä»·æ ¼ç”¨mean

---

### 5.4 df.rolling() â­â­â­

**åŠŸèƒ½**: åˆ›å»ºæ»šåŠ¨çª—å£ï¼Œç”¨äºè®¡ç®—ç§»åŠ¨å¹³å‡ç­‰

**è¯­æ³•**:
```python
df.rolling(window, min_periods=None).agg_func()
```

**å‚æ•°**:
- `window`: çª—å£å¤§å°ï¼ˆæ•´æ•°æˆ–æ—¶é—´åç§»ï¼‰
- `min_periods`: æœ€å°è§‚æµ‹æ•°

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'value': [10, 20, 30, 40, 50]
})

# 3å¤©ç§»åŠ¨å¹³å‡
df['ma_3'] = df['value'].rolling(window=3).mean()
#    value  ma_3
# 0     10   NaN
# 1     20   NaN
# 2     30  20.0  # (10+20+30)/3
# 3     40  30.0  # (20+30+40)/3
# 4     50  40.0  # (30+40+50)/3

# ç§»åŠ¨æ±‚å’Œ
df['sum_3'] = df['value'].rolling(window=3).sum()

# ç§»åŠ¨æ ‡å‡†å·®
df['std_3'] = df['value'].rolling(window=3).std()

# æœ€å°è§‚æµ‹æ•°
df['ma_3'] = df['value'].rolling(window=3, min_periods=1).mean()
#    value  ma_3
# 0     10  10.0  # åªæœ‰1ä¸ªå€¼
# 1     20  15.0  # (10+20)/2
# 2     30  20.0  # (10+20+30)/3
```

**æ—¶é—´çª—å£**:
```python
# æŒ‰æ—¶é—´çª—å£ï¼ˆè€Œéè¡Œæ•°ï¼‰
df = df.set_index(pd.to_datetime(df['date']))
df['ma_7d'] = df['value'].rolling('7D').mean()  # 7å¤©ç§»åŠ¨å¹³å‡
```

**é¢è¯•çœŸé¢˜åº”ç”¨**:
```python
# é¢˜ç›®4: 7æ—¥ç§»åŠ¨å¹³å‡
def analyze_timeseries(df):
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.set_index('timestamp')

    daily_avg = df.resample('D').mean()

    # 7æ—¥ç§»åŠ¨å¹³å‡
    daily_avg['rolling_7d'] = daily_avg['value'].rolling(window=7).mean()

    return daily_avg
```

**å¸¸è§åº”ç”¨**:
```python
# è‚¡ç¥¨åˆ†æ
df['SMA_20'] = df['close'].rolling(20).mean()  # 20æ—¥å‡çº¿
df['SMA_50'] = df['close'].rolling(50).mean()  # 50æ—¥å‡çº¿

# å¼‚å¸¸æ£€æµ‹
df['rolling_mean'] = df['value'].rolling(7).mean()
df['rolling_std'] = df['value'].rolling(7).std()
df['upper_bound'] = df['rolling_mean'] + 2 * df['rolling_std']
df['lower_bound'] = df['rolling_mean'] - 2 * df['rolling_std']

# é”€å”®è¶‹åŠ¿
df['sales_ma_30'] = df['daily_sales'].rolling(30).mean()
```

**é¢è¯•è¦ç‚¹**:
- ç”¨äºå¹³æ»‘æ•°æ®ã€è¯†åˆ«è¶‹åŠ¿
- å‰é¢çš„è¡Œä¼šæ˜¯NaNï¼ˆå› ä¸ºçª—å£ä¸å¤Ÿï¼‰
- å¯ä»¥ä½¿ç”¨ `min_periods` æ§åˆ¶æœ€å°è§‚æµ‹æ•°
- å¸¸ä¸æ—¶é—´åºåˆ—ç»“åˆä½¿ç”¨

---

### 5.5 df.pct_change()

**åŠŸèƒ½**: è®¡ç®—ç™¾åˆ†æ¯”å˜åŒ–ï¼ˆç¯æ¯”å¢é•¿ç‡ï¼‰

**è¯­æ³•**:
```python
df.pct_change(periods=1)
```

**å‚æ•°**:
- `periods`: è®¡ç®—å˜åŒ–çš„å‘¨æœŸæ•°

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'value': [100, 110, 120, 115, 130]
})

# è®¡ç®—ç¯æ¯”å¢é•¿ç‡
df['growth'] = df['value'].pct_change()
#    value    growth
# 0    100       NaN
# 1    110  0.100000  # (110-100)/100 = 10%
# 2    120  0.090909  # (120-110)/110 = 9.09%
# 3    115 -0.041667  # (115-120)/120 = -4.17%
# 4    130  0.130435  # (130-115)/115 = 13.04%

# è½¬æ¢ä¸ºç™¾åˆ†æ¯”
df['growth_pct'] = df['value'].pct_change() * 100

# ä¸2æœŸå‰æ¯”è¾ƒ
df['growth_2'] = df['value'].pct_change(periods=2)
```

**é¢è¯•çœŸé¢˜åº”ç”¨**:
```python
# é¢˜ç›®4: æœˆåº¦ç¯æ¯”å¢é•¿
def analyze_timeseries(df):
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.set_index('timestamp')

    # æŒ‰æœˆèšåˆ
    monthly = df.resample('M').sum()

    # æœˆåº¦ç¯æ¯”å¢é•¿
    monthly['mom_growth'] = monthly['value'].pct_change() * 100

    return monthly
```

**å¸¸è§åº”ç”¨**:
```python
# é”€å”®ç¯æ¯”å¢é•¿
monthly_sales['mom_growth'] = monthly_sales['sales'].pct_change() * 100

# åŒæ¯”å¢é•¿ï¼ˆä¸å»å¹´åŒæœŸæ¯”è¾ƒï¼‰
daily_sales['yoy_growth'] = daily_sales['sales'].pct_change(periods=365) * 100

# ç”¨æˆ·å¢é•¿ç‡
df['user_growth'] = df['active_users'].pct_change() * 100
```

**é¢è¯•è¦ç‚¹**:
- ç¬¬ä¸€è¡Œæ€»æ˜¯NaN
- è¿”å›å°æ•°ï¼Œä¹˜ä»¥100å¾—åˆ°ç™¾åˆ†æ¯”
- å¯ä»¥è®¾ç½® periods è®¡ç®—ä¸åŒå‘¨æœŸçš„å˜åŒ–
- å¸¸ç”¨äºåˆ†æå¢é•¿è¶‹åŠ¿

---

## 6. æ•°æ®åˆå¹¶å’Œå…³è”

### 6.1 df.merge() â­â­â­â­â­

**åŠŸèƒ½**: ç±»ä¼¼SQLçš„JOINæ“ä½œï¼Œåˆå¹¶ä¸¤ä¸ªDataFrame

**è¯­æ³•**:
```python
df1.merge(df2, on=None, how='inner', left_on=None, right_on=None)
```

**å‚æ•°**:
- `on`: è¿æ¥çš„åˆ—åï¼ˆä¸¤ä¸ªè¡¨åˆ—åç›¸åŒæ—¶ï¼‰
- `how`: 'inner'(å†…è¿æ¥) | 'left'(å·¦è¿æ¥) | 'right'(å³è¿æ¥) | 'outer'(å…¨å¤–è¿æ¥)
- `left_on`: å·¦è¡¨çš„è¿æ¥åˆ—
- `right_on`: å³è¡¨çš„è¿æ¥åˆ—

**å››ç§è¿æ¥ç±»å‹**:
```python
left = pd.DataFrame({
    'key': ['A', 'B', 'C'],
    'value1': [1, 2, 3]
})

right = pd.DataFrame({
    'key': ['B', 'C', 'D'],
    'value2': [4, 5, 6]
})

# å†…è¿æ¥ï¼ˆåªä¿ç•™åŒ¹é…çš„ï¼‰
left.merge(right, on='key', how='inner')
#   key  value1  value2
# 0   B       2       4
# 1   C       3       5

# å·¦è¿æ¥ï¼ˆä¿ç•™å·¦è¡¨æ‰€æœ‰è¡Œï¼‰
left.merge(right, on='key', how='left')
#   key  value1  value2
# 0   A       1     NaN
# 1   B       2     4.0
# 2   C       3     5.0

# å³è¿æ¥ï¼ˆä¿ç•™å³è¡¨æ‰€æœ‰è¡Œï¼‰
left.merge(right, on='key', how='right')
#   key  value1  value2
# 0   B     2.0       4
# 1   C     3.0       5
# 2   D     NaN       6

# å…¨å¤–è¿æ¥ï¼ˆä¿ç•™æ‰€æœ‰è¡Œï¼‰
left.merge(right, on='key', how='outer')
#   key  value1  value2
# 0   A     1.0     NaN
# 1   B     2.0     4.0
# 2   C     3.0     5.0
# 3   D     NaN     6.0
```

**åˆ—åä¸åŒæ—¶**:
```python
# ä½¿ç”¨ left_on å’Œ right_on
orders.merge(
    customers,
    left_on='customer_id',
    right_on='id',
    how='left'
)
```

**å¤šåˆ—è¿æ¥**:
```python
df1.merge(df2, on=['key1', 'key2'], how='inner')
```

**é¢è¯•çœŸé¢˜åº”ç”¨**:
```python
# é¢˜ç›®5: å¤šè¡¨å…³è”
def merge_order_data(orders, customers, products):
    """åˆå¹¶è®¢å•ã€å®¢æˆ·ã€äº§å“ä¸‰ä¸ªè¡¨"""

    # ç¬¬ä¸€æ­¥ï¼šè®¢å• + å®¢æˆ·
    result = orders.merge(customers, on='customer_id', how='left')

    # ç¬¬äºŒæ­¥ï¼šç»“æœ + äº§å“
    result = result.merge(products, on='product_id', how='left')

    # é€‰æ‹©éœ€è¦çš„åˆ—
    result = result[['order_id', 'customer_name', 'product_name',
                     'quantity', 'price', 'order_date']]

    return result
```

**å¸¸è§è¿æ¥åœºæ™¯**:
```python
# 1. è®¢å•è¡¨ + å®¢æˆ·è¡¨
orders.merge(customers, on='customer_id', how='left')

# 2. é”€å”®è¡¨ + äº§å“è¡¨ + ç±»åˆ«è¡¨
sales.merge(products, on='product_id') \
     .merge(categories, on='category_id')

# 3. äº‹å®è¡¨ + å¤šä¸ªç»´åº¦è¡¨
fact.merge(dim_date, on='date_id') \
    .merge(dim_product, on='product_id') \
    .merge(dim_customer, on='customer_id')
```

**å¤„ç†é‡å¤åˆ—å**:
```python
# å¦‚æœä¸¤ä¸ªè¡¨æœ‰åŒååˆ—ï¼Œä¼šè‡ªåŠ¨æ·»åŠ åç¼€
result = df1.merge(df2, on='id', suffixes=('_left', '_right'))
```

**é¢è¯•è¦ç‚¹**:
- **è¶…é«˜é¢‘è€ƒç‚¹**ï¼Œå¿…é¡»æŒæ¡
- ç†è§£å››ç§è¿æ¥ç±»å‹çš„åŒºåˆ«
- left join æœ€å¸¸ç”¨ï¼ˆä¿ç•™ä¸»è¡¨æ‰€æœ‰æ•°æ®ï¼‰
- å¯ä»¥è¿æ¥å¤šä¸ªè¡¨ï¼ˆé“¾å¼è°ƒç”¨ï¼‰
- äº†è§£å¦‚ä½•å¤„ç†åˆ—åå†²çª

---

## 7. æ–‡ä»¶è¯»å†™

### 7.1 pd.read_csv()

**åŠŸèƒ½**: ä»CSVæ–‡ä»¶è¯»å–æ•°æ®åˆ°DataFrame

**è¯­æ³•**:
```python
pd.read_csv(filepath, sep=',', header='infer', names=None, usecols=None)
```

**å¸¸ç”¨å‚æ•°**:
- `filepath`: æ–‡ä»¶è·¯å¾„
- `sep`: åˆ†éš”ç¬¦ï¼ˆé»˜è®¤é€—å·ï¼‰
- `header`: è¡¨å¤´è¡Œå·ï¼ˆNoneè¡¨ç¤ºæ— è¡¨å¤´ï¼‰
- `names`: è‡ªå®šä¹‰åˆ—å
- `usecols`: åªè¯»å–æŒ‡å®šåˆ—
- `dtype`: æŒ‡å®šåˆ—çš„æ•°æ®ç±»å‹
- `parse_dates`: å°†æŒ‡å®šåˆ—è§£æä¸ºæ—¥æœŸ

**åŸºæœ¬ç¤ºä¾‹**:
```python
# è¯»å–CSVæ–‡ä»¶
df = pd.read_csv('data.csv')

# æŒ‡å®šåˆ†éš”ç¬¦
df = pd.read_csv('data.txt', sep='\t')

# æ— è¡¨å¤´
df = pd.read_csv('data.csv', header=None, names=['A', 'B', 'C'])

# åªè¯»å–éƒ¨åˆ†åˆ—
df = pd.read_csv('data.csv', usecols=['name', 'age', 'city'])

# æŒ‡å®šæ•°æ®ç±»å‹
df = pd.read_csv('data.csv', dtype={'id': str, 'age': int})

# è§£ææ—¥æœŸåˆ—
df = pd.read_csv('data.csv', parse_dates=['date'])
```

**å¤„ç†ç¼ºå¤±å€¼**:
```python
# æŒ‡å®šç¼ºå¤±å€¼æ ‡è®°
df = pd.read_csv('data.csv', na_values=['NA', 'missing', '-'])

# ä¸åŒåˆ—ä½¿ç”¨ä¸åŒçš„ç¼ºå¤±å€¼æ ‡è®°
df = pd.read_csv('data.csv', na_values={'col1': ['NA'], 'col2': ['-']})
```

**å¤§æ–‡ä»¶å¤„ç†**:
```python
# åˆ†å—è¯»å–
for chunk in pd.read_csv('large_file.csv', chunksize=10000):
    process(chunk)

# åªè¯»å–å‰Nè¡Œ
df = pd.read_csv('data.csv', nrows=1000)
```

**é¢è¯•è¦ç‚¹**:
- äº†è§£å¸¸ç”¨å‚æ•°
- çŸ¥é“å¦‚ä½•å¤„ç†ä¸åŒæ ¼å¼çš„æ–‡ä»¶
- å¤§æ–‡ä»¶ä½¿ç”¨ chunksize

---

### 7.2 df.to_csv()

**åŠŸèƒ½**: å°†DataFrameä¿å­˜ä¸ºCSVæ–‡ä»¶

**è¯­æ³•**:
```python
df.to_csv(filepath, sep=',', index=True, header=True)
```

**å‚æ•°**:
- `filepath`: æ–‡ä»¶è·¯å¾„
- `sep`: åˆ†éš”ç¬¦
- `index`: æ˜¯å¦ä¿å­˜ç´¢å¼•
- `header`: æ˜¯å¦ä¿å­˜åˆ—å
- `encoding`: ç¼–ç æ ¼å¼

**ç¤ºä¾‹**:
```python
# ä¿å­˜åˆ°CSVï¼ˆä¸ä¿å­˜ç´¢å¼•ï¼‰
df.to_csv('output.csv', index=False)

# æŒ‡å®šåˆ†éš”ç¬¦
df.to_csv('output.txt', sep='\t', index=False)

# æŒ‡å®šç¼–ç 
df.to_csv('output.csv', index=False, encoding='utf-8')

# åªä¿å­˜éƒ¨åˆ†åˆ—
df[['name', 'age']].to_csv('output.csv', index=False)

# è¿½åŠ åˆ°æ–‡ä»¶
df.to_csv('output.csv', mode='a', header=False, index=False)
```

**é¢è¯•çœŸé¢˜åº”ç”¨**:
```python
# é¢˜ç›®21: ETLæµç¨‹
def process_csv_file(input_file, output_file):
    # è¯»å–
    df = pd.read_csv(input_file)

    # æ¸…æ´—
    df = df.drop_duplicates()
    df = df.dropna(subset=['id'])

    # å¯¼å‡º
    df.to_csv(output_file, index=False)
```

---

### 7.3 pd.to_numeric()

**åŠŸèƒ½**: å°†åˆ—è½¬æ¢ä¸ºæ•°å€¼ç±»å‹

**è¯­æ³•**:
```python
pd.to_numeric(arg, errors='raise', downcast=None)
```

**å‚æ•°**:
- `errors`: 'raise'(æŠ¥é”™) | 'coerce'(æ— æ•ˆå€¼å˜ä¸ºNaN) | 'ignore'(ä¿æŒåŸæ ·)

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'A': ['1', '2', '3', 'abc'],
    'B': ['100', '200', 'xyz', '400']
})

# è½¬æ¢ï¼Œæ— æ•ˆå€¼å˜ä¸ºNaN
df['A'] = pd.to_numeric(df['A'], errors='coerce')
#      A
# 0  1.0
# 1  2.0
# 2  3.0
# 3  NaN

# æ‰¹é‡è½¬æ¢å¤šåˆ—
for col in ['A', 'B']:
    df[col] = pd.to_numeric(df[col], errors='coerce')
```

**é¢è¯•åº”ç”¨**:
```python
# ETLä¸­çš„ç±»å‹è½¬æ¢
df['amount'] = pd.to_numeric(df['amount'], errors='coerce')
df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce').fillna(0).astype(int)
```

---

## 8. æ•°æ®éªŒè¯

### 8.1 df.isnull() / df.isna()

**åŠŸèƒ½**: æ£€æŸ¥ç¼ºå¤±å€¼ï¼Œè¿”å›å¸ƒå°”DataFrame

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'A': [1, np.nan, 3],
    'B': [4, 5, np.nan]
})

# æ£€æŸ¥æ¯ä¸ªå€¼æ˜¯å¦ä¸ºç©º
df.isnull()
#        A      B
# 0  False  False
# 1   True  False
# 2  False   True

# ç»Ÿè®¡æ¯åˆ—çš„ç¼ºå¤±å€¼æ•°é‡
df.isnull().sum()
# A    1
# B    1

# ç»Ÿè®¡æ€»ç¼ºå¤±å€¼
df.isnull().sum().sum()  # 2

# æ£€æŸ¥æŸåˆ—æ˜¯å¦æœ‰ç¼ºå¤±
df['A'].isnull().any()  # True

# ç­›é€‰æœ‰ç¼ºå¤±å€¼çš„è¡Œ
df[df['A'].isnull()]
```

**é¢è¯•åº”ç”¨**:
```python
# æ•°æ®è´¨é‡æ£€æŸ¥
def check_data_quality(df):
    print("Missing values per column:")
    print(df.isnull().sum())

    print(f"\nTotal missing: {df.isnull().sum().sum()}")
    print(f"Missing percentage: {df.isnull().sum().sum() / df.size * 100:.2f}%")
```

**é¢è¯•è¦ç‚¹**:
- `isnull()` å’Œ `isna()` å®Œå…¨ç›¸åŒ
- å¸¸ä¸ `sum()` ç»“åˆç»Ÿè®¡ç¼ºå¤±å€¼
- å¯ä»¥ç”¨ `notnull()` æˆ– `notna()` æ£€æŸ¥éç©º

---

### 8.2 pd.notna() / pd.notnull()

**åŠŸèƒ½**: æ£€æŸ¥éç¼ºå¤±å€¼

**ç¤ºä¾‹**:
```python
df = pd.DataFrame({
    'A': [1, np.nan, 3],
    'B': [4, 5, np.nan]
})

# æ£€æŸ¥éç©º
df.notna()
#        A      B
# 0   True   True
# 1  False   True
# 2   True  False

# ç»Ÿè®¡éç©ºå€¼æ•°é‡
df.notna().sum()
# A    2
# B    2

# ç­›é€‰éç©ºè¡Œ
df[df['A'].notna()]
```

**é¢è¯•åº”ç”¨**:
```python
# é¢˜ç›®20: æ•°æ®éªŒè¯
def validate_data(df):
    errors = {}

    # æ£€æŸ¥å¿…å¡«åˆ—çš„ç©ºå€¼
    for col in ['id', 'name']:
        null_indices = df[df[col].isnull()].index.tolist()
        if null_indices:
            errors[col] = null_indices

    return errors
```

---

## 9. Numpy å¸¸ç”¨å‡½æ•°

### 9.1 np.nan

**åŠŸèƒ½**: è¡¨ç¤ºç¼ºå¤±å€¼ï¼ˆNot a Numberï¼‰

**ç¤ºä¾‹**:
```python
import numpy as np
import pandas as pd

# åˆ›å»ºåŒ…å«ç¼ºå¤±å€¼çš„æ•°æ®
data = {
    'A': [1, 2, np.nan, 4],
    'B': [5, np.nan, 7, 8]
}
df = pd.DataFrame(data)

# æ£€æŸ¥æ˜¯å¦ä¸ºNaN
pd.isna(np.nan)  # True
np.isnan(np.nan)  # True

# æ¯”è¾ƒ
np.nan == np.nan  # Falseï¼ˆNaNä¸ç­‰äºä»»ä½•å€¼ï¼ŒåŒ…æ‹¬è‡ªå·±ï¼‰
```

**é¢è¯•è¦ç‚¹**:
- Pandasä¸­ç”¨ `np.nan` è¡¨ç¤ºç¼ºå¤±å€¼
- NaN != NaNï¼ˆå¿…é¡»ç”¨ `pd.isna()` æˆ– `np.isnan()` åˆ¤æ–­ï¼‰
- ç®—æœ¯è¿ç®—ä¸­ï¼ŒNaNä¼šä¼ æ’­ï¼ˆä»»ä½•æ•°ä¸NaNè¿ç®—ç»“æœéƒ½æ˜¯NaNï¼‰

---

### 9.2 np.random ç³»åˆ—

**åŠŸèƒ½**: ç”Ÿæˆéšæœºæ•°

**å¸¸ç”¨å‡½æ•°**:
```python
import numpy as np

# éšæœºæ•´æ•°
np.random.randint(low, high, size)
np.random.randint(1, 10, 5)  # [3, 7, 2, 9, 1]

# å‡åŒ€åˆ†å¸ƒ
np.random.uniform(low, high, size)
np.random.uniform(0, 1, 5)  # [0.23, 0.67, 0.91, ...]

# æ­£æ€åˆ†å¸ƒ
np.random.normal(loc, scale, size)
np.random.normal(100, 15, 1000)  # å‡å€¼100ï¼Œæ ‡å‡†å·®15

# å¯¹æ•°æ­£æ€åˆ†å¸ƒ
np.random.lognormal(mean, sigma, size)
np.random.lognormal(5, 1.5, 1000)

# éšæœºé€‰æ‹©
np.random.choice(array, size, replace=True, p=None)
np.random.choice(['A', 'B', 'C'], size=10)
np.random.choice([1,2,3], size=5, p=[0.5, 0.3, 0.2])  # å¸¦æ¦‚ç‡

# æ‰“ä¹±æ•°ç»„
arr = np.array([1, 2, 3, 4, 5])
np.random.shuffle(arr)  # åŸåœ°æ‰“ä¹±
```

**è®¾ç½®éšæœºç§å­**:
```python
# ä¿è¯å¯é‡ç°
np.random.seed(42)
np.random.randint(1, 10, 5)  # æ¯æ¬¡è¿è¡Œç»“æœç›¸åŒ
```

**é¢è¯•åº”ç”¨**:
```python
# ç”Ÿæˆæµ‹è¯•æ•°æ®
dates = pd.date_range('2024-01-01', periods=30, freq='D')
df = pd.DataFrame({
    'date': dates,
    'value': np.random.randint(100, 200, 30),
    'category': np.random.choice(['A', 'B', 'C'], 30)
})

# ç”Ÿæˆé‡‘èæ•°æ®
amounts = np.random.lognormal(mean=5, sigma=1.5, size=1000)
```

---

### 9.3 å…¶ä»–å¸¸ç”¨Numpyå‡½æ•°

**æ•°ç»„è¿æ¥**:
```python
# è¿æ¥æ•°ç»„
arr1 = np.array([1, 2, 3])
arr2 = np.array([4, 5, 6])
np.concatenate([arr1, arr2])  # [1, 2, 3, 4, 5, 6]

# å‚ç›´å †å 
np.vstack([arr1, arr2])
# [[1, 2, 3],
#  [4, 5, 6]]
```

**æ•°ç»„ç»Ÿè®¡**:
```python
arr = np.array([1, 2, 3, 4, 5])

np.mean(arr)    # 3.0
np.median(arr)  # 3.0
np.std(arr)     # 1.414...
np.sum(arr)     # 15
np.min(arr)     # 1
np.max(arr)     # 5
```

---

## 10. é¢è¯•é«˜é¢‘ç»„åˆæŠ€å·§

### 10.1 å®Œæ•´çš„æ•°æ®æ¸…æ´—æµç¨‹

```python
def clean_dataframe(df):
    """æ ‡å‡†æ•°æ®æ¸…æ´—æµç¨‹"""
    print(f"åŸå§‹æ•°æ®: {len(df)} è¡Œ")

    # 1. åˆ é™¤å®Œå…¨é‡å¤çš„è¡Œ
    df = df.drop_duplicates()
    print(f"å»é‡å: {len(df)} è¡Œ")

    # 2. å¤„ç†ç¼ºå¤±å€¼
    # 2.1 åˆ é™¤å…³é”®åˆ—ä¸ºç©ºçš„è¡Œ
    df = df.dropna(subset=['id', 'date'])

    # 2.2 æ•°å€¼åˆ—ç”¨å‡å€¼/ä¸­ä½æ•°å¡«å……
    for col in df.select_dtypes(include=[np.number]).columns:
        if df[col].isnull().sum() > 0:
            df[col].fillna(df[col].median(), inplace=True)

    # 2.3 åˆ†ç±»åˆ—ç”¨ä¼—æ•°å¡«å……
    for col in df.select_dtypes(include=['object']).columns:
        if df[col].isnull().sum() > 0:
            df[col].fillna(df[col].mode()[0], inplace=True)

    # 3. ç±»å‹è½¬æ¢
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df['amount'] = pd.to_numeric(df['amount'], errors='coerce')

    # 4. åˆ é™¤å¼‚å¸¸å€¼ï¼ˆ3ÏƒåŸåˆ™ï¼‰
    for col in ['amount', 'quantity']:
        if col in df.columns:
            mean = df[col].mean()
            std = df[col].std()
            df = df[(df[col] >= mean - 3*std) & (df[col] <= mean + 3*std)]

    # 5. é‡ç½®ç´¢å¼•
    df = df.reset_index(drop=True)

    print(f"æ¸…æ´—å: {len(df)} è¡Œ")
    return df
```

---

### 10.2 åˆ†ç»„èšåˆå¸¸è§æ¨¡å¼

```python
# æ¨¡å¼1: å•ç»´åº¦å¤šæŒ‡æ ‡
summary = df.groupby('category').agg({
    'sales': ['sum', 'mean', 'count'],
    'revenue': 'sum',
    'quantity': 'mean'
}).reset_index()

# æ¨¡å¼2: å¤šç»´åº¦åˆ†ç»„
summary = df.groupby(['region', 'category']).agg({
    'sales': 'sum'
}).reset_index()

# æ¨¡å¼3: è‡ªå®šä¹‰èšåˆ
def custom_agg(x):
    return x.max() - x.min()

summary = df.groupby('product')['price'].agg([
    ('avg', 'mean'),
    ('total', 'sum'),
    ('range', custom_agg)
]).reset_index()
```

---

### 10.3 æ—¶é—´åºåˆ—åˆ†ææµç¨‹

```python
def analyze_timeseries(df):
    """å®Œæ•´çš„æ—¶é—´åºåˆ—åˆ†æ"""
    # 1. è½¬æ¢æ—¥æœŸç±»å‹
    df['date'] = pd.to_datetime(df['date'])
    df = df.set_index('date')

    # 2. æŒ‰æ—¥èšåˆ
    daily = df.resample('D').sum()

    # 3. ç§»åŠ¨å¹³å‡
    daily['ma_7'] = daily['value'].rolling(7).mean()
    daily['ma_30'] = daily['value'].rolling(30).mean()

    # 4. æœˆåº¦æ±‡æ€»
    monthly = df.resample('M').sum()
    monthly['mom_growth'] = monthly['value'].pct_change() * 100

    # 5. åŒæ¯”å¢é•¿ï¼ˆä¸å»å¹´æ¯”ï¼‰
    monthly['yoy_growth'] = monthly['value'].pct_change(periods=12) * 100

    return daily, monthly
```

---

### 10.4 å¤šè¡¨å…³è”æ ‡å‡†æ¨¡å¼

```python
def merge_multiple_tables(fact, dim1, dim2, dim3):
    """å¤šè¡¨å…³è”æ ‡å‡†æµç¨‹"""
    result = (fact
              .merge(dim1, on='dim1_id', how='left')
              .merge(dim2, on='dim2_id', how='left')
              .merge(dim3, on='dim3_id', how='left'))

    # é€‰æ‹©éœ€è¦çš„åˆ—
    result = result[[
        'id', 'dim1_name', 'dim2_name', 'dim3_name',
        'value', 'date'
    ]]

    return result
```

---

## 11. é¢è¯•é€Ÿè®°å¡ç‰‡ â­

### å¿…è®°å‡½æ•°ï¼ˆæŒ‰é¢‘ç‡æ’åºï¼‰

| å‡½æ•° | ç”¨é€” | é¢‘ç‡ |
|------|------|------|
| `drop_duplicates()` | åˆ é™¤é‡å¤è¡Œ | â­â­â­â­â­ |
| `groupby().agg()` | åˆ†ç»„èšåˆ | â­â­â­â­â­ |
| `merge()` | è¡¨è¿æ¥ | â­â­â­â­â­ |
| `fillna()` | å¡«å……ç¼ºå¤±å€¼ | â­â­â­â­â­ |
| `dropna()` | åˆ é™¤ç¼ºå¤±å€¼ | â­â­â­â­ |
| `pivot()` | æ•°æ®é€è§† | â­â­â­â­ |
| `resample()` | æ—¶é—´é‡é‡‡æ · | â­â­â­ |
| `rolling()` | æ»šåŠ¨çª—å£ | â­â­â­ |
| `to_datetime()` | æ—¥æœŸè½¬æ¢ | â­â­â­â­ |
| `sort_values()` | æ’åº | â­â­â­â­ |

---

### å¿«é€Ÿè®°å¿†å£è¯€

**æ•°æ®æ¸…æ´—ä¸‰éƒ¨æ›²**:
1. `drop_duplicates()` - å»é‡
2. `fillna()` / `dropna()` - å¤„ç†ç¼ºå¤±
3. `reset_index()` - é‡ç½®ç´¢å¼•

**åˆ†ç»„èšåˆä¸‰æ­¥éª¤**:
1. `groupby()` - åˆ†ç»„
2. `.agg()` - èšåˆ
3. `.reset_index()` - è¿˜åŸç´¢å¼•

**æ—¶é—´åºåˆ—å››ä»¶å¥—**:
1. `to_datetime()` - è½¬æ¢ç±»å‹
2. `set_index()` - è®¾ç½®ç´¢å¼•
3. `resample()` - é‡é‡‡æ ·
4. `rolling()` - ç§»åŠ¨å¹³å‡

**å¤šè¡¨å…³è”æ ‡å‡†æµç¨‹**:
1. `merge(table1, on='key', how='left')`
2. `merge(table2, on='key', how='left')`
3. é€‰æ‹©éœ€è¦çš„åˆ—

---

## 12. å¸¸è§é”™è¯¯å’Œæ³¨æ„äº‹é¡¹ âš ï¸

### é”™è¯¯1: å¿˜è®° reset_index()

```python
# âŒ é”™è¯¯
result = df.groupby('category')['sales'].sum()
# ç»“æœæ˜¯ Seriesï¼Œcategoryæ˜¯ç´¢å¼•

# âœ… æ­£ç¡®
result = df.groupby('category')['sales'].sum().reset_index()
# ç»“æœæ˜¯ DataFrameï¼Œcategoryæ˜¯æ™®é€šåˆ—
```

### é”™è¯¯2: inplace=True æ²¡æœ‰è¿”å›å€¼

```python
# âŒ é”™è¯¯
df = df.drop_duplicates(inplace=True)  # dfå˜æˆNone

# âœ… æ­£ç¡®ï¼ˆä¸¤ç§æ–¹å¼é€‰ä¸€ç§ï¼‰
df = df.drop_duplicates()  # inplace=Falseï¼Œè¿”å›æ–°DF
# æˆ–
df.drop_duplicates(inplace=True)  # ä¸è¦èµ‹å€¼
```

### é”™è¯¯3: æ—¶é—´åºåˆ—æ²¡æœ‰è®¾ç½®ç´¢å¼•

```python
# âŒ é”™è¯¯
df.resample('D').mean()  # æŠ¥é”™ï¼šæ²¡æœ‰DatetimeIndex

# âœ… æ­£ç¡®
df['date'] = pd.to_datetime(df['date'])
df = df.set_index('date')
df.resample('D').mean()  # OK
```

### é”™è¯¯4: mergeååˆ—åå†²çª

```python
# âŒ é—®é¢˜ï¼šä¸¤ä¸ªè¡¨éƒ½æœ‰'name'åˆ—
result = df1.merge(df2, on='id')
# ç»“æœï¼šname_x, name_y å¾ˆæ··ä¹±

# âœ… è§£å†³ï¼šæŒ‡å®šåç¼€
result = df1.merge(df2, on='id', suffixes=('_customer', '_product'))
# ç»“æœï¼šname_customer, name_product
```

---

## 13. é¢è¯•å‰æœ€åæ£€æŸ¥æ¸…å• âœ…

- [ ] èƒ½å¿«é€Ÿå†™å‡ºæ•°æ®æ¸…æ´—æµç¨‹ï¼ˆå»é‡ã€å¡«å……ã€åˆ é™¤ï¼‰
- [ ] ç†Ÿç»ƒä½¿ç”¨ groupby + agg è¿›è¡Œåˆ†ç»„èšåˆ
- [ ] ç†è§£å››ç§ merge è¿æ¥ç±»å‹çš„åŒºåˆ«
- [ ] çŸ¥é“å¦‚ä½•å¤„ç†æ—¶é—´åºåˆ—ï¼ˆto_datetime + set_index + resampleï¼‰
- [ ] ä¼šç”¨ pivot è¿›è¡Œæ•°æ®é€è§†
- [ ] äº†è§£ rolling è®¡ç®—ç§»åŠ¨å¹³å‡
- [ ] è®°ä½å¸¸ç”¨èšåˆå‡½æ•°ï¼šsum, mean, count, min, max
- [ ] çŸ¥é“å¦‚ä½•æ£€æŸ¥å’Œå¤„ç†ç¼ºå¤±å€¼
- [ ] èƒ½è¯»å†™CSVæ–‡ä»¶å¹¶è¿›è¡Œç±»å‹è½¬æ¢
- [ ] ç†è§£ reset_index() çš„ä½œç”¨å’Œä½¿ç”¨æ—¶æœº

---

**ç¥ä½ é¢è¯•æˆåŠŸï¼ Good luck! ğŸ’ªğŸš€**
